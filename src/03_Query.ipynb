{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Query\n",
    "- 構築した検索インデックスをクエリして回答を生成する。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case\n",
    "- 内閣府のAI戦略ドキュメントをインプットデータとする。\n",
    "  - https://www8.cao.go.jp/cstp/ai/index.html\n",
    "- ドキュメントには、テキスト、テーブル、図、グラフなどが含まれており、それらをもとにした回答ができるようなRAGアプリケーションを構築する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents==11.6.0b4\n",
    "! pip install python-dotenv langchain langchain-community langchain-openai langchainhub openai tiktoken azure-ai-documentintelligence azure-identity azure-ai-textanalytics promptflow-evals promptflow-azure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AIServicesVisionParameters,\n",
    "    AIServicesVisionVectorizer,\n",
    "    AIStudioModelCatalogName,\n",
    "    AzureMachineLearningVectorizer,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIModelName,\n",
    "    AzureOpenAIParameters,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    BlobIndexerDataToExtract,\n",
    "    BlobIndexerParsingMode,\n",
    "    CognitiveServicesAccountKey,\n",
    "    DefaultCognitiveServicesAccount,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    IndexerExecutionStatus,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    InputFieldMappingEntry,\n",
    "    KeyPhraseExtractionSkill,\n",
    "    OutputFieldMappingEntry,\n",
    "    ScalarQuantizationCompressionConfiguration,\n",
    "    ScalarQuantizationParameters,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    SplitSkill,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    "    VisionVectorizeSkill\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    HybridCountAndFacetMode,\n",
    "    HybridSearch,\n",
    "    SearchScoreThreshold,\n",
    "    VectorizableTextQuery,\n",
    "    VectorizableImageBinaryQuery,\n",
    "    VectorizableImageUrlQuery,\n",
    "    VectorSimilarityThreshold,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "from IPython.display import Image, display, HTML\n",
    "from openai import AzureOpenAI\n",
    "from azure.ai.textanalytics import TextAnalyticsClient\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "from langchain import hub\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from langchain.schema import StrOutputParser\n",
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.vectorstores.azuresearch import AzureSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Configuration\n",
    "AZURE_AI_VISION_API_KEY = os.getenv(\"AZURE_AI_VISION_API_KEY\")\n",
    "AZURE_AI_VISION_ENDPOINT = os.getenv(\"AZURE_AI_VISION_ENDPOINT\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "STORAGE_ACCOUNT_NAME = os.getenv(\"STORAGE_ACCOUNT_NAME\")\n",
    "BLOB_CONTAINER_NAME = \"rag-knowledge-03-business\"\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "INDEX_NAME = \"rag-search-index-push-03\"\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")\n",
    "AZURE_AI_MULTI_SERVICE_ENDPOINT = os.getenv(\"AZURE_AI_MULTI_SERVICE_ENDPOINT\")\n",
    "AZURE_AI_MULTI_SERVICE_KEY = os.getenv(\"AZURE_AI_MULTI_SERVICE_KEY\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "AZURE_DOCUMENT_INTELLIGENCE_KEY = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "SUBSCRIPTION_ID = os.getenv(\"SUBSCRIPTION_ID\")\n",
    "RESOURCE_GROUP_NAME = os.getenv(\"RESOURCE_GROUP_NAME\")\n",
    "PROJECT_NAME = os.getenv(\"PROJECT_NAME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query-Design\n",
    "Tips for Azure AI Search Query-Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "検索手法・クエリ設計ごとにパイプラインを構築します。それぞれ以下の仕様です。\n",
    "\n",
    "#### Keyword Search Pipeline\n",
    "- **目的**: キーワードによるシンプルな検索を行う。\n",
    "- **特徴**: クエリを再構成し、シンプルなキーワード検索を実施。高精度な情報検索を行うのではなく、関連する結果を素早く取得するための手法。\n",
    "- **他との違い**: キーワードマッチングを用いた検索で、ベクトル検索やセマンティックランカーを使用しないため、実装がシンプルで軽量。\n",
    "\n",
    "#### Vector Search Pipeline\n",
    "- **目的**: クエリの意味的な類似性に基づく検索を行う。\n",
    "- **特徴**: クエリをベクトル化し、データベース内のベクトルと類似度の高いものを検索。リランキングの処理を経ないため、より迅速に関連度の高い結果を返す。\n",
    "- **他との違い**: キーワードベースの検索ではなく、意味的な類似性を評価するため、より柔軟で直感的な検索が可能。\n",
    "\n",
    "#### Hybrid Search Pipeline\n",
    "- **目的**: キーワード検索とベクトル検索の利点を組み合わせて、より豊かな検索結果を提供する。\n",
    "- **特徴**: キーワード検索とベクトル検索を同時に実行し、結果を統合する。これにより、テキストの意味的な側面と明示的なキーワードを考慮した検索が可能。\n",
    "- **他との違い**: キーワードとベクトル検索の両方の特性を活かし、幅広い検索ニーズに対応する。\n",
    "\n",
    "#### Hybrid Search + Semantic Ranker Pipeline\n",
    "- **目的**: ハイブリッド検索の結果をセマンティックランカーでリランキングし、最も関連性の高い結果を提供する。\n",
    "- **特徴**: セマンティックランカーを使用して検索結果をリランキングすることで、ユーザーの意図により忠実な検索結果を返す。\n",
    "- **他との違い**: セマンティックランカーの導入により、検索結果の精度が向上し、特に長いクエリや複雑な意図のクエリに対して有効。\n",
    "\n",
    "#### RAG with HyDE Pipeline\n",
    "- **目的**: ユーザーの質問に対してより的確な回答を生成するために、Hypothetical Document Embedding (HyDE) を使用する。\n",
    "- **特徴**: クエリに対して仮説的な回答を生成し、それをもとにベクトル検索を実行。これにより、より関連性の高い文書を検索し、ユーザーの質問に応答。\n",
    "- **他との違い**: HyDE の仮説生成機能を利用することで、クエリの明示的な回答が存在しない場合でも、有益な検索結果を生成する能力が向上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified parameter\n",
    "USE_AAD_FOR_SEARCH = False  # Set this to False to use API key for authentication\n",
    "\n",
    "def authenticate_azure_search(api_key=None, use_aad_for_search=False):\n",
    "    if use_aad_for_search:\n",
    "        print(\"Using AAD for authentication.\")\n",
    "        credential = DefaultAzureCredential()\n",
    "    else:\n",
    "        print(\"Using API keys for authentication.\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"API key must be provided if not using AAD for authentication.\")\n",
    "        credential = AzureKeyCredential(api_key)\n",
    "    return credential\n",
    "\n",
    "azure_search_credential = authenticate_azure_search(api_key=AZURE_SEARCH_ADMIN_KEY, use_aad_for_search=USE_AAD_FOR_SEARCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    system_message = f\"\"\"\n",
    "    system:\n",
    "\tYou are an AI assistant that helps users answer questions given a specific context. You will be given a context and asked a question based on that context. Your answer should be as precise as possible and should only come from the context.\n",
    "\tYou must generate a response in markdown format. You must include the image url for showing the image in the response, if the context corresponding to the answer contains \"image_url\".\n",
    "\tPlease add citation after each sentence when possible in a form \"(Source: citation)\".\n",
    "\tcontext: {context}\n",
    "\tuser: \n",
    "\t\"\"\"\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": query}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\t# response_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = \"\"\"\n",
    "# Your Task\n",
    "- Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\n",
    "- You must output json format.\n",
    "\n",
    "# Json format example:\n",
    "{\n",
    "\t\"questions\": [\n",
    "\t\t\"rephrase question content ....\",\n",
    "\t]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def generate_rephrase_query(text):\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": text}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o-mini\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\tresponse_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = \"\"\"\n",
    "# Your Task\n",
    "- Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\n",
    "- You also need to extend the original question to generate 5 related queries. This is done to capture the broader context of the user's question.\n",
    "- You must output json format. In other words, You must output array of questions that length is 5.\n",
    "\n",
    "# Json format example:\n",
    "{\n",
    "\t\"questions\": [\n",
    "\t\t\"related question 1\",\n",
    "\t\t\"related question 2\",\n",
    "\t\t\"related question 3\",\n",
    "\t\t\"related question 4\",\n",
    "\t\t\"related question 5\"\n",
    "\t]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def generate_expanded_query(text):\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": text}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o-mini\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\tresponse_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_hypothetical_query(text):\n",
    "    hypothetical_gen_instruction = f\"\"\"Please write a passage to answer the question\n",
    "\tQuestion: {text}\n",
    "\tPassage:\n",
    "\t\"\"\"\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": \"You are an AI assistant.\"},\n",
    "\t\t{\"role\":\"user\",\"content\": hypothetical_gen_instruction}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o-mini\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\t# response_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=azure_search_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define keyword search pipeline\n",
    "def keyword_search_pipeline(search_client, search_text):\n",
    "    # Perform the search\n",
    "    search_text_rephrased = json.loads(generate_rephrase_query(search_text))[\"questions\"][0]\n",
    "    results = search_client.search(\n",
    "        query_type='simple',  # without semantic ranker\n",
    "        query_language='ja',\n",
    "        search_text=search_text_rephrased,\n",
    "        top=5,\n",
    "        select=\"content, title, image_url\",\n",
    "        search_fields=[\"content\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "    \n",
    "    # Collecting search results\n",
    "    context_text = \"\"\n",
    "    retrieved_results = []\n",
    "    for result in results:\n",
    "        context_text += result[\"content\"] + \" \"\n",
    "        retrieved_results.append({\n",
    "            \"title\": result.get(\"title\"),\n",
    "            \"content\": result.get(\"content\"),\n",
    "            \"image_url\": result.get(\"image_url\")\n",
    "        })\n",
    "    \n",
    "    # Generate the final answer\n",
    "    final_answer = generate_answer(search_text_rephrased, context_text)\n",
    "    \n",
    "    # Return a dictionary with prompt, retrieved results, and the final answer\n",
    "    return {\n",
    "        \"prompt\": search_text,\n",
    "        \"rephrased_prompt\": search_text_rephrased,\n",
    "        \"retrieved_results\": retrieved_results,\n",
    "        \"final_answer\": final_answer\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define vector search pipeline\n",
    "def vector_search_pipeline(search_client, search_text):\n",
    "    # Rephrase the search text\n",
    "    search_text_rephrased = json.loads(generate_rephrase_query(search_text))[\"questions\"][0]\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=search_text_rephrased,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"vector\",\n",
    "    )\n",
    "    \n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        search_text=None,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"content, title, image_url\",\n",
    "    )\n",
    "    \n",
    "    # Collecting search results\n",
    "    context_text = \"\"\n",
    "    retrieved_results = []\n",
    "    for result in results:\n",
    "        context_text += result[\"content\"] + \" \"\n",
    "        retrieved_results.append({\n",
    "            \"title\": result.get(\"title\"),\n",
    "            \"content\": result.get(\"content\"),\n",
    "            \"image_url\": result.get(\"image_url\")\n",
    "        })\n",
    "    \n",
    "    # Generate the final answer\n",
    "    final_answer = generate_answer(search_text_rephrased, context_text)\n",
    "    \n",
    "    # Return a dictionary with prompt, retrieved results, and the final answer\n",
    "    return {\n",
    "        \"prompt\": search_text,\n",
    "        \"rephrased_prompt\": search_text_rephrased,\n",
    "        \"retrieved_results\": retrieved_results,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hybrid search pipeline\n",
    "def hybrid_search_pipeline(search_client, search_text):\n",
    "    # Rephrase the search text\n",
    "    search_text_rephrased = json.loads(generate_rephrase_query(search_text))[\"questions\"][0]\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=search_text_rephrased,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"vector\",\n",
    "    )\n",
    "    \n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        query_type='simple',  # without semantic ranker\n",
    "        query_language='ja',\n",
    "        search_text=search_text_rephrased,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"content, title, image_url\",\n",
    "        search_fields=[\"content\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "    \n",
    "    # Collecting search results\n",
    "    context_text = \"\"\n",
    "    retrieved_results = []\n",
    "    for result in results:\n",
    "        context_text += result[\"content\"] + \" \"\n",
    "        retrieved_results.append({\n",
    "            \"title\": result.get(\"title\"),\n",
    "            \"content\": result.get(\"content\"),\n",
    "            \"image_url\": result.get(\"image_url\")\n",
    "        })\n",
    "    \n",
    "    # Generate the final answer\n",
    "    final_answer = generate_answer(search_text_rephrased, context_text)\n",
    "    \n",
    "    # Return a dictionary with prompt, retrieved results, and the final answer\n",
    "    return {\n",
    "        \"prompt\": search_text,\n",
    "        \"rephrased_prompt\": search_text_rephrased,\n",
    "        \"retrieved_results\": retrieved_results,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Hybrid search + Semantic Ranker pipeline\n",
    "def hybrid_semantic_pipeline(search_client, search_text):\n",
    "    # Rephrase the search text\n",
    "    search_text_rephrased = json.loads(generate_rephrase_query(search_text))[\"questions\"][0]\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=search_text_rephrased,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"vector\",\n",
    "    )\n",
    "    \n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        query_type='semantic',\n",
    "        query_language='ja',\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        search_text=search_text_rephrased,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"content, title, image_url\",\n",
    "        search_fields=[\"content\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "    \n",
    "    # Collecting search results\n",
    "    context_text = \"\"\n",
    "    retrieved_results = []\n",
    "    for result in results:\n",
    "        context_text += result[\"content\"] + \" \"\n",
    "        retrieved_results.append({\n",
    "            \"title\": result.get(\"title\"),\n",
    "            \"content\": result.get(\"content\"),\n",
    "            \"image_url\": result.get(\"image_url\")\n",
    "        })\n",
    "    \n",
    "    # Generate the final answer\n",
    "    final_answer = generate_answer(search_text_rephrased, context_text)\n",
    "    \n",
    "    # Return a dictionary with prompt, retrieved results, and the final answer\n",
    "    return {\n",
    "        \"prompt\": search_text,\n",
    "        \"rephrased_prompt\": search_text_rephrased,\n",
    "        \"retrieved_results\": retrieved_results,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG with HyDE Pipeline\n",
    "def rag_pipeline_with_hyde(search_client, search_text):\n",
    "    # Generate a hypothetical answer\n",
    "    hypothetical_answer = generate_hypothetical_query(search_text)\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=hypothetical_answer,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"vector\",\n",
    "    )\n",
    "    \n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        query_type='semantic',\n",
    "        query_language='ja',\n",
    "        semantic_configuration_name='my-semantic-config',\n",
    "        search_text=hypothetical_answer,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"content, title, image_url\",\n",
    "        search_fields=[\"content\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "    \n",
    "    # Collecting search results\n",
    "    context_text = \"\"\n",
    "    retrieved_results = []\n",
    "    for result in results:\n",
    "        context_text += result[\"content\"] + \" \"\n",
    "        retrieved_results.append({\n",
    "            \"title\": result.get(\"title\"),\n",
    "            \"content\": result.get(\"content\"),\n",
    "            \"image_url\": result.get(\"image_url\")\n",
    "        })\n",
    "    \n",
    "    # Generate the final answer\n",
    "    final_answer = generate_answer(search_text, context_text)\n",
    "    \n",
    "    # Return a dictionary with the query, hypothetical answer, retrieved results, and the final answer\n",
    "    return {\n",
    "        \"prompt\": search_text,\n",
    "        \"rephrased_prompt\": hypothetical_answer,\n",
    "        \"retrieved_results\": retrieved_results,\n",
    "        \"final_answer\": final_answer\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_ai_project = { \n",
    "    \"subscription_id\": SUBSCRIPTION_ID,\n",
    "    \"resource_group_name\": RESOURCE_GROUP_NAME,\n",
    "    \"project_name\": PROJECT_NAME\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_var = {\n",
    "    \"gpt-4o\": {\n",
    "        \"endpoint\": f\"{AZURE_OPENAI_ENDPOINT}/deployments/gpt-4o/chat/completions?api-version=2024-02-01\",\n",
    "        \"key\": f\"{AZURE_OPENAI_API_KEY}\",\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_input = pd.read_json(\"../eval/03/input/eval_data.jsonl\", lines=True)\n",
    "df_eval_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "output_folder = \"../eval/03/output\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "\tos.makedirs(output_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame to store the results\n",
    "df_eval_output = df_eval_input.copy()\n",
    "\n",
    "# Execute the hybrid_semantic_pipeline function for each question\n",
    "for index, row in df_eval_output.iterrows():\n",
    "\tquestion = row['question']\n",
    "\t\n",
    "\t# RAG with hybrid semantic pipeline\n",
    "\tresult = hybrid_semantic_pipeline(search_client, question)\n",
    "\t\n",
    "\t# Add the result to the DataFrame\n",
    "\tdf_eval_output.at[index, 'rephrased_prompt'] = result['rephrased_prompt']\n",
    "\tdf_eval_output.at[index, 'retrieved_results'] = json.dumps(result['retrieved_results'], ensure_ascii=False)\n",
    "\tdf_eval_output.at[index, 'answer'] = result['final_answer']\n",
    "\n",
    "# Save the new DataFrame\n",
    "df_eval_output.to_json(\"../eval/03/output/eval_output.jsonl\", orient=\"records\", lines=True, force_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure AI Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from promptflow.core import AzureOpenAIModelConfiguration\n",
    "\n",
    "configuration = AzureOpenAIModelConfiguration(\n",
    "    azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "    api_key=AZURE_OPENAI_API_KEY,\n",
    "    api_version=\"2024-02-01\",\n",
    "    azure_deployment=\"gpt-4o\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eval.app_target import ModelEndpoints\n",
    "import pathlib\n",
    "import random\n",
    "\n",
    "from promptflow.evals.evaluate import evaluate\n",
    "from promptflow.evals.evaluators import (\n",
    "    ContentSafetyEvaluator,\n",
    "    RelevanceEvaluator,\n",
    "    CoherenceEvaluator,\n",
    "    GroundednessEvaluator,\n",
    "    FluencyEvaluator,\n",
    "    SimilarityEvaluator,\n",
    ")\n",
    "\n",
    "\n",
    "content_safety_evaluator = ContentSafetyEvaluator(project_scope=azure_ai_project)\n",
    "relevance_evaluator = RelevanceEvaluator(model_config=configuration)\n",
    "coherence_evaluator = CoherenceEvaluator(model_config=configuration)\n",
    "groundedness_evaluator = GroundednessEvaluator(model_config=configuration)\n",
    "fluency_evaluator = FluencyEvaluator(model_config=configuration)\n",
    "similarity_evaluator = SimilarityEvaluator(model_config=configuration)\n",
    "\n",
    "models = [\n",
    "    \"gpt-4o\",\n",
    "]\n",
    "\n",
    "path = \"../eval/03/output/eval_output.jsonl\"\n",
    "\n",
    "for model in models:\n",
    "    randomNum = random.randint(1111, 9999)\n",
    "    results = evaluate(\n",
    "        azure_ai_project=azure_ai_project,\n",
    "        evaluation_name=\"Eval-Run-\" + str(randomNum) + \"-\" + model.title(),\n",
    "        data=path,\n",
    "        # target=ModelEndpoints(env_var, model),\n",
    "        evaluators={\n",
    "            # \"content_safety\": content_safety_evaluator,\n",
    "            \"coherence\": coherence_evaluator,\n",
    "            \"relevance\": relevance_evaluator,\n",
    "            \"groundedness\": groundedness_evaluator,\n",
    "            \"fluency\": fluency_evaluator,\n",
    "            \"similarity\": similarity_evaluator,\n",
    "        },\n",
    "        evaluator_config={\n",
    "            # \"content_safety\": {\"question\": \"${data.question}\", \"answer\": \"${data.answer}\"},\n",
    "            \"coherence\": {\"answer\": \"${data.answer}\", \"question\": \"${data.question}\"},\n",
    "            \"relevance\": {\"answer\": \"${data.answer}\", \"context\": \"${data.context}\", \"question\": \"${data.question}\"},\n",
    "            \"groundedness\": {\n",
    "                \"answer\": \"${data.answer}\",\n",
    "                \"context\": \"${data.context}\",\n",
    "                \"question\": \"${data.question}\",\n",
    "            },\n",
    "            \"fluency\": {\"answer\": \"${data.answer}\", \"context\": \"${data.context}\", \"question\": \"${data.question}\"},\n",
    "            \"similarity\": {\"answer\": \"${data.answer}\", \"ground_truth\": \"${data.ground_truth}\", \"question\": \"${data.question}\"},\n",
    "        },\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
