{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Search Pull Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02_Chunking Optimization\n",
    "Tips for Chunking Optimization to create search indexes for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use case\n",
    "- Azure AI Search の サービス仕様ドキュメントをインプットにする。\n",
    "  - https://learn.microsoft.com/ja-jp/azure/search/\n",
    "- ドキュメントは OCR が必要。\n",
    "- 開発者マニュアルは、構造化されたセクションとなっている。\n",
    "- 各セクションは非常に詳細かつ専門性の高い技術解説が記載されており、ドキュメントサイズも大きい。\n",
    "- ドキュメントには、テキスト、テーブル、図、グラフなどが含まれるが、ここでは、テキスト、テーブルデータのみを扱う。\n",
    "\n",
    "## チャンキング設計\n",
    "- Document Intelligence で、Markdown形式でテキストデータを抽出済み。\n",
    "- 1つのドキュメントに大量のコンテキストが含まれており、ドキュメントサイズも大きいため、チャンキングを実施する。\n",
    "- ドキュメントは、技術要素ごとに明確なセクションわけがされており、各セクションで見るとLLMが扱えないレベルのデータサイズではない。そのため、セクション単位でチャンキングする。\n",
    "- 各チャンキングのContentはEmbeddingする。\n",
    "- Overlapping は行わない。\n",
    "- 広い意味のコンテキストを保持するために、上位2つのヘッダー（Markdown形式：#, ##）をメタデータとして保持する。例えば、検索インデックスに関する記載があった場合に、それが「キーワード検索」に属する情報なのか、「ベクトル検索」に属する情報なのかを判断するために保持する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install azure-search-documents==11.6.0b4\n",
    "! pip install openai python-dotenv azure-identity cohere azure-ai-vision-imageanalysis\n",
    "! pip install azure-storage-blob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.identity import DefaultAzureCredential, get_bearer_token_provider\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.indexes import SearchIndexClient, SearchIndexerClient\n",
    "from azure.search.documents.indexes.models import (\n",
    "    AIServicesVisionParameters,\n",
    "    AIServicesVisionVectorizer,\n",
    "    AIStudioModelCatalogName,\n",
    "    AzureMachineLearningVectorizer,\n",
    "    AzureOpenAIVectorizer,\n",
    "    AzureOpenAIModelName,\n",
    "    AzureOpenAIParameters,\n",
    "    AzureOpenAIEmbeddingSkill,\n",
    "    BlobIndexerDataToExtract,\n",
    "    BlobIndexerParsingMode,\n",
    "    CognitiveServicesAccountKey,\n",
    "    DefaultCognitiveServicesAccount,\n",
    "    ExhaustiveKnnAlgorithmConfiguration,\n",
    "    ExhaustiveKnnParameters,\n",
    "    FieldMapping,\n",
    "    HnswAlgorithmConfiguration,\n",
    "    HnswParameters,\n",
    "    IndexerExecutionStatus,\n",
    "    IndexingParameters,\n",
    "    IndexingParametersConfiguration,\n",
    "    InputFieldMappingEntry,\n",
    "    KeyPhraseExtractionSkill,\n",
    "    OutputFieldMappingEntry,\n",
    "    ScalarQuantizationCompressionConfiguration,\n",
    "    ScalarQuantizationParameters,\n",
    "    SearchField,\n",
    "    SearchFieldDataType,\n",
    "    SearchIndex,\n",
    "    SearchIndexer,\n",
    "    SearchIndexerDataContainer,\n",
    "    SearchIndexerDataIdentity,\n",
    "    SearchIndexerDataSourceConnection,\n",
    "    SearchIndexerIndexProjections,\n",
    "    SearchIndexerIndexProjectionSelector,\n",
    "    SearchIndexerIndexProjectionsParameters,\n",
    "    SearchIndexerSkillset,\n",
    "    SemanticConfiguration,\n",
    "    SemanticField,\n",
    "    SemanticPrioritizedFields,\n",
    "    SemanticSearch,\n",
    "    SimpleField,\n",
    "    SplitSkill,\n",
    "    VectorSearch,\n",
    "    VectorSearchAlgorithmKind,\n",
    "    VectorSearchAlgorithmMetric,\n",
    "    VectorSearchProfile,\n",
    "    VisionVectorizeSkill\n",
    ")\n",
    "from azure.search.documents.models import (\n",
    "    HybridCountAndFacetMode,\n",
    "    HybridSearch,\n",
    "    SearchScoreThreshold,\n",
    "    VectorizableTextQuery,\n",
    "    VectorizableImageBinaryQuery,\n",
    "    VectorizableImageUrlQuery,\n",
    "    VectorSimilarityThreshold,\n",
    ")\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display, HTML\n",
    "from openai import AzureOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configuration\n",
    "AZURE_AI_VISION_API_KEY = os.getenv(\"AZURE_AI_VISION_API_KEY\")\n",
    "AZURE_AI_VISION_ENDPOINT = os.getenv(\"AZURE_AI_VISION_ENDPOINT\")\n",
    "AZURE_OPENAI_ENDPOINT = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "BLOB_CONNECTION_STRING = os.getenv(\"BLOB_CONNECTION_STRING\")\n",
    "INDEX_NAME = \"rag-search-index-pull-0621\"\n",
    "AZURE_SEARCH_ADMIN_KEY = os.getenv(\"AZURE_SEARCH_ADMIN_KEY\")\n",
    "AZURE_SEARCH_ENDPOINT = os.getenv(\"AZURE_SEARCH_ENDPOINT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# User-specified parameter\n",
    "USE_AAD_FOR_SEARCH = False  # Set this to False to use API key for authentication\n",
    "\n",
    "def authenticate_azure_search(api_key=None, use_aad_for_search=False):\n",
    "    if use_aad_for_search:\n",
    "        print(\"Using AAD for authentication.\")\n",
    "        credential = DefaultAzureCredential()\n",
    "    else:\n",
    "        print(\"Using API keys for authentication.\")\n",
    "        if api_key is None:\n",
    "            raise ValueError(\"API key must be provided if not using AAD for authentication.\")\n",
    "        credential = AzureKeyCredential(api_key)\n",
    "    return credential\n",
    "\n",
    "azure_search_credential = authenticate_azure_search(api_key=AZURE_SEARCH_ADMIN_KEY, use_aad_for_search=USE_AAD_FOR_SEARCH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データセットのアップロード\n",
    "Azure AI Search のインデクサーにより、データをインポートする場合は各データソースにデータを格納しておく必要がある。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.azure_blob_operation import upload_folder_to_blob\n",
    "\n",
    "connection_string = BLOB_CONNECTION_STRING\n",
    "container_name = \"rag-knowledge-01-aisearch\"\n",
    "local_folder_path = \"../output/\"\n",
    "\n",
    "upload_folder_to_blob(connection_string, container_name, local_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a blob data source connector on Azure AI Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_or_update_data_source(indexer_client, container_name, connection_string, index_name):\n",
    "    \"\"\"\n",
    "    Create or update a data source connection for Azure AI Search.\n",
    "    \"\"\"\n",
    "    container = SearchIndexerDataContainer(name=container_name)\n",
    "    data_source_connection = SearchIndexerDataSourceConnection(\n",
    "        name=f\"{index_name}-blob\",\n",
    "        type=\"azureblob\",\n",
    "        connection_string=connection_string,\n",
    "        container=container\n",
    "    )\n",
    "    try:\n",
    "        indexer_client.create_or_update_data_source_connection(data_source_connection)\n",
    "        print(f\"Data source '{index_name}-blob' created or updated successfully.\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"Failed to create or update data source due to error: {e}\")\n",
    "\n",
    "# Create a SearchIndexerClient instance\n",
    "indexer_client = SearchIndexerClient(AZURE_SEARCH_ENDPOINT, azure_search_credential)\n",
    "\n",
    "# Call the function to create or update the data source\n",
    "create_or_update_data_source(indexer_client, container_name, BLOB_CONNECTION_STRING, INDEX_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a search index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fields():\n",
    "    \"\"\"Creates the fields for the search index based on the specified schema.\"\"\"\n",
    "    return [\n",
    "        SimpleField(\n",
    "            name=\"id\", type=SearchFieldDataType.String, key=True, filterable=True\n",
    "        ),\n",
    "        SearchField(name=\"content\", type=SearchFieldDataType.String, searchable=True, analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(\n",
    "\t\t\tname=\"content_vector\",\n",
    "\t\t\ttype=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "\t\t\tvector_search_dimensions=1536,\n",
    "\t\t\tvector_search_profile_name=\"myHnswProfile\",\n",
    "\t\t\tstored=False,\n",
    "\t\t),\n",
    "        SearchField(name=\"metadata\", type=SearchFieldDataType.String, searchable=True, analyzer_name=\"ja.microsoft\"),\n",
    "        SearchField(name=\"title\", type=SearchFieldDataType.String, searchable=True, analyzer_name=\"ja.microsoft\"),\n",
    "    ]\n",
    "\n",
    "\n",
    "def create_vector_search_configuration():\n",
    "    \"\"\"Creates the vector search configuration.\"\"\"\n",
    "    return VectorSearch(\n",
    "        algorithms=[\n",
    "            HnswAlgorithmConfiguration(\n",
    "                name=\"myHnsw\",\n",
    "                parameters=HnswParameters(\n",
    "                    m=4,\n",
    "                    ef_construction=400,\n",
    "                    ef_search=500,\n",
    "                    metric=VectorSearchAlgorithmMetric.COSINE,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        compressions=[\n",
    "            ScalarQuantizationCompressionConfiguration(\n",
    "                name=\"myScalarQuantization\",\n",
    "                rerank_with_original_vectors=True,\n",
    "                default_oversampling=10,\n",
    "                parameters=ScalarQuantizationParameters(quantized_data_type=\"int8\"),\n",
    "            )\n",
    "        ],\n",
    "        vectorizers=[\n",
    "            AzureOpenAIVectorizer(\n",
    "                name=\"myAzureOpenAIVectorizer\",\n",
    "                kind=\"azureOpenAI\",\n",
    "                azure_open_ai_parameters=AzureOpenAIParameters(\n",
    "                    resource_uri=AZURE_OPENAI_ENDPOINT,\n",
    "                    api_key=AZURE_OPENAI_API_KEY,\n",
    "                    deployment_id=\"text-embedding-ada-002\",\n",
    "                    model_name=AzureOpenAIModelName.TEXT_EMBEDDING_ADA002,\n",
    "                ),\n",
    "            )\n",
    "        ],\n",
    "        profiles=[\n",
    "            VectorSearchProfile(\n",
    "                name=\"myHnswProfile\",\n",
    "                algorithm_configuration_name=\"myHnsw\",\n",
    "                compression_configuration_name=\"myScalarQuantization\",\n",
    "                vectorizer=\"myAzureOpenAIVectorizer\",\n",
    "            )\n",
    "        ],\n",
    "    )\n",
    "\n",
    "\n",
    "def create_search_index(index_client, index_name, fields, vector_search):\n",
    "    \"\"\"Creates or updates a search index.\"\"\"\n",
    "    index = SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=fields,\n",
    "        vector_search=vector_search,\n",
    "    )\n",
    "    index_client.create_or_update_index(index=index)\n",
    "\n",
    "\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential\n",
    ")\n",
    "fields = create_fields()\n",
    "vector_search = create_vector_search_configuration()\n",
    "\n",
    "# Create the search index with the adjusted schema\n",
    "create_search_index(index_client, INDEX_NAME, fields, vector_search)\n",
    "print(f\"Created index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_index(index_name, azure_openai_endpoint, azure_openai_embedding_deployment_id, azure_openai_key=None):\n",
    "    return SearchIndex(\n",
    "        name=index_name,\n",
    "        fields=[\n",
    "            SearchField(\n",
    "                name=\"chunk_id\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                key=True,\n",
    "                hidden=False,\n",
    "                filterable=True,\n",
    "                sortable=True,\n",
    "                facetable=False,\n",
    "                searchable=True,\n",
    "                analyzer_name=\"keyword\"\n",
    "            ),\n",
    "            SearchField(\n",
    "                name=\"parent_id\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                hidden=False,\n",
    "                filterable=True,\n",
    "                sortable=True,\n",
    "                facetable=False,\n",
    "                searchable=True\n",
    "            ),\n",
    "            SearchField(\n",
    "                name=\"chunk\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                hidden=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                searchable=True,\n",
    "                analyzer_name=\"ja.microsoft\" # replace with your analyzer\n",
    "            ),\n",
    "            SearchField(\n",
    "                name=\"title\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                hidden=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                searchable=True,\n",
    "                analyzer_name=\"ja.microsoft\" # replace with your analyzer\n",
    "            ),\n",
    "            SearchField(\n",
    "                name=\"key_phrases\",\n",
    "                type=SearchFieldDataType.String,\n",
    "                hidden=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                searchable=True,\n",
    "                analyzer_name=\"ja.microsoft\" # replace with your analyzer\n",
    "            ),\n",
    "            SearchField(\n",
    "                name=\"vector\",\n",
    "                type=SearchFieldDataType.Collection(SearchFieldDataType.Single),\n",
    "                hidden=False,\n",
    "                filterable=False,\n",
    "                sortable=False,\n",
    "                facetable=False,\n",
    "                searchable=True,\n",
    "                vector_search_dimensions=1536,\n",
    "                vector_search_profile_name=\"profile\"\n",
    "            )\n",
    "        ],\n",
    "        vector_search=VectorSearch(\n",
    "\t\t\talgorithms=[\n",
    "\t\t\t\tHnswAlgorithmConfiguration(\n",
    "\t\t\t\t\tname=\"myHnsw\",\n",
    "\t\t\t\t\tparameters=HnswParameters(\n",
    "\t\t\t\t\t\tm=4,\n",
    "\t\t\t\t\t\tef_construction=400,\n",
    "\t\t\t\t\t\tef_search=500,\n",
    "\t\t\t\t\t\tmetric=VectorSearchAlgorithmMetric.COSINE,\n",
    "\t\t\t\t\t),\n",
    "\t\t\t\t)\n",
    "\t\t\t],\n",
    "\t\t\tcompressions=[\n",
    "\t\t\t\tScalarQuantizationCompressionConfiguration(\n",
    "\t\t\t\t\tname=\"myScalarQuantization\",\n",
    "\t\t\t\t\trerank_with_original_vectors=True,\n",
    "\t\t\t\t\tdefault_oversampling=10,\n",
    "\t\t\t\t\tparameters=ScalarQuantizationParameters(quantized_data_type=\"int8\"),\n",
    "\t\t\t\t)\n",
    "\t\t\t],\n",
    "\t\t\tvectorizers=[\n",
    "\t\t\t\tAzureOpenAIVectorizer(\n",
    "\t\t\t\t\tname=\"myAzureOpenAIVectorizer\",\n",
    "\t\t\t\t\tkind=\"azureOpenAI\",\n",
    "\t\t\t\t\tazure_open_ai_parameters=AzureOpenAIParameters(\n",
    "\t\t\t\t\t\tresource_uri=azure_openai_endpoint,\n",
    "\t\t\t\t\t\tapi_key=azure_openai_key,\n",
    "\t\t\t\t\t\tdeployment_id=azure_openai_embedding_deployment_id,\n",
    "\t\t\t\t\t\tmodel_name=AzureOpenAIModelName.TEXT_EMBEDDING_ADA002,\n",
    "\t\t\t\t\t),\n",
    "\t\t\t\t)\n",
    "\t\t\t],\n",
    "\t\t\tprofiles=[\n",
    "\t\t\t\tVectorSearchProfile(\n",
    "\t\t\t\t\tname=\"profile\",\n",
    "\t\t\t\t\talgorithm_configuration_name=\"myHnsw\",\n",
    "\t\t\t\t\tcompression_configuration_name=\"myScalarQuantization\",\n",
    "\t\t\t\t\tvectorizer=\"myAzureOpenAIVectorizer\",\n",
    "\t\t\t\t)\n",
    "\t\t\t],\n",
    "    \t)\n",
    "\t)\n",
    "\n",
    "index = create_search_index(\n",
    "    INDEX_NAME,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    \"text-embedding-ada-002\", # replace with your deployment name\n",
    "    AZURE_OPENAI_API_KEY\n",
    ")\n",
    "index_client = SearchIndexClient(\n",
    "    endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential\n",
    ")\n",
    "index_client.create_or_update_index(index)\n",
    "\n",
    "print(f\"Created index: {INDEX_NAME}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Skillset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_skillset(\n",
    "        skillset_name,\n",
    "        index_name,\n",
    "        azure_openai_endpoint,\n",
    "        azure_openai_embedding_deployment_id,\n",
    "        azure_openai_key=None,\n",
    "        text_split_mode='pages',\n",
    "        maximum_page_length=2000,\n",
    "        page_overlap_length=500):\n",
    "    return SearchIndexerSkillset(\n",
    "        name=skillset_name,\n",
    "        skills=[\n",
    "            SplitSkill(\n",
    "                name=\"Text Splitter\",\n",
    "                default_language_code=\"ja\", # replace documents language code\n",
    "                text_split_mode=text_split_mode,\n",
    "                maximum_page_length=maximum_page_length,\n",
    "                page_overlap_length=page_overlap_length,\n",
    "                context=\"/document\",\n",
    "                inputs=[\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"text\",\n",
    "                        source=\"/document/content\"\n",
    "                    )\n",
    "                ],\n",
    "                outputs=[\n",
    "                    OutputFieldMappingEntry(\n",
    "                        name=\"textItems\",\n",
    "                        target_name=\"pages\"\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            AzureOpenAIEmbeddingSkill(\n",
    "                name=\"Embeddings\",\n",
    "                resource_uri=azure_openai_endpoint,\n",
    "                deployment_id=azure_openai_embedding_deployment_id,\n",
    "                api_key=azure_openai_key, # Optional if using RBAC authentication\n",
    "                model_name=AzureOpenAIModelName.TEXT_EMBEDDING_ADA002,\n",
    "                context=\"/document/pages/*\",\n",
    "                inputs=[\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"text\",\n",
    "                        source=\"/document/pages/*\"\n",
    "                    )\n",
    "                ],\n",
    "                outputs=[\n",
    "                    OutputFieldMappingEntry(\n",
    "                        name=\"embedding\",\n",
    "                        target_name=\"vector\"\n",
    "                    )\n",
    "                ]\n",
    "            ),\n",
    "            KeyPhraseExtractionSkill(\n",
    "\t\t\t\tname=\"Key Phrase Extraction\",\n",
    "\t\t\t\tcontext=\"/document/pages/*\",\n",
    "\t\t\t\tdefault_language_code=\"ja\", # replace documents language code\n",
    "                inputs=[\n",
    "                    InputFieldMappingEntry(\n",
    "                        name=\"text\",\n",
    "                        source=\"/document/pages/*\"\n",
    "                    )\n",
    "                ],\n",
    "                outputs=[\n",
    "                    OutputFieldMappingEntry(\n",
    "                        name=\"keyPhrases\",\n",
    "                        target_name=\"key_phrases\"\n",
    "                    )\n",
    "                ]\n",
    "\t\t\t)\n",
    "        ],\n",
    "        index_projections=SearchIndexerIndexProjections(\n",
    "            selectors=[\n",
    "                SearchIndexerIndexProjectionSelector(\n",
    "                    target_index_name=index_name,\n",
    "                    parent_key_field_name=\"parent_id\",\n",
    "                    source_context=\"/document/pages/*\",\n",
    "                    mappings=[\n",
    "                        InputFieldMappingEntry(\n",
    "                            name=\"chunk\",\n",
    "                            source=\"/document/pages/*\"\n",
    "                        ),\n",
    "                        InputFieldMappingEntry(\n",
    "                            name=\"vector\",\n",
    "                            source=\"/document/pages/*/vector\"\n",
    "                        ),\n",
    "                        InputFieldMappingEntry(\n",
    "                            name=\"title\",\n",
    "                            source=\"/document/metadata_storage_name\"\n",
    "                        ),\n",
    "                        InputFieldMappingEntry(\n",
    "                            name=\"key_phrases\",\n",
    "                            source=\"/document/pages/*/key_phrases\"\n",
    "                        ),\n",
    "                    ]\n",
    "                )\n",
    "            ],\n",
    "            parameters=SearchIndexerIndexProjectionsParameters(projection_mode=\"skipIndexingParentDocuments\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "skillset_name = f\"{INDEX_NAME}-skillset\"\n",
    "skillset = create_search_skillset(\n",
    "    skillset_name,\n",
    "    INDEX_NAME,\n",
    "    AZURE_OPENAI_ENDPOINT,\n",
    "    \"text-embedding-ada-002\", # replace with your deployment name\n",
    "    AZURE_OPENAI_API_KEY,\n",
    "    text_split_mode='pages',\n",
    "    maximum_page_length=2000,\n",
    "    page_overlap_length=500\n",
    ")\n",
    "search_indexer_client = SearchIndexerClient(endpoint=AZURE_SEARCH_ENDPOINT, credential=azure_search_credential)\n",
    "search_indexer_client.create_or_update_skillset(skillset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Indexer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_search_indexer(indexer_name, skillset_name, datasource_name, index_name):\n",
    "    return SearchIndexer(\n",
    "        name=indexer_name,\n",
    "        data_source_name=datasource_name,\n",
    "        target_index_name=index_name,\n",
    "        skillset_name=skillset_name\n",
    "    )\n",
    "\n",
    "indexer_name = f\"{INDEX_NAME}-indexer\"\n",
    "indexer = create_search_indexer(indexer_name, skillset_name, f\"{INDEX_NAME}-blob\", INDEX_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_indexer_client.create_or_update_indexer(indexer)\n",
    "print(f\"{indexer_name} created or updated.\")\n",
    "search_indexer_client.run_indexer(indexer_name)\n",
    "print(f\"{indexer_name} is running. If queries return no results, please wait a bit and try again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04_Query-Design\n",
    "Tips for Azure AI Search Query-Design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Search\n",
    "- ユーザのクエリのコンテキストをとらえたい、かつサービスに特化したワードがクエリに含まれる可能性が高いため、フルテキスト検索＋ベクトル検索を組み合わせたHybrid検索を採用する。\n",
    "  - Hybrid検索のスコアはAzure AI Searchでは、Reciprocal Rank Fusion (RRF) が採用される。 \n",
    "- クエリはユーザのクエリをそのまま検索インデックスのクエリに利用する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_client = SearchClient(endpoint=AZURE_SEARCH_ENDPOINT, index_name=INDEX_NAME, credential=azure_search_credential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"ベクトル検索時の設定要素について教えてください\"\n",
    "\n",
    "vector_query = VectorizableTextQuery(\n",
    "    text=query,\n",
    "    k_nearest_neighbors=50,\n",
    "    fields=\"vector\",\n",
    ")\n",
    "\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    top=5,\n",
    "    select=\"chunk, title, key_phrases\",\n",
    "\tsearch_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query Extensions\n",
    "- ユーザのクエリのコンテキストをとらえたい、かつサービスに特化したワードがクエリに含まれる可能性が高いため、フルテキスト検索＋ベクトル検索を組み合わせたHybrid検索を採用する。\n",
    "  - Hybrid検索のスコアはAzure AI Searchでは、Reciprocal Rank Fusion (RRF) が採用される。 \n",
    "- また、ユーザクエリから検索クエリを新しく生成する。\n",
    "  - クエリはユーザのクエリをスタンドアローンなクエリに変換する。\n",
    "  - また、検索のカバレッジを大きくするために、類似した入力クエリを複数生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = \"\"\"\n",
    "# Your Task\n",
    "- Given the following conversation history and the users next question,rephrase the question to be a stand alone question.\n",
    "- You also need to extend the original question to generate 5 related queries. This is done to capture the broader context of the user's question.\n",
    "- You must output json format. In other words, You must output array of questions that length is 5.\n",
    "\n",
    "# Json format example:\n",
    "{\n",
    "\t\"questions\": [\n",
    "\t\t\"related question 1\",\n",
    "\t\t\"related question 2\",\n",
    "\t\t\"related question 3\",\n",
    "\t\t\"related question 4\",\n",
    "\t\t\"related question 5\"\n",
    "\t]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "def generate_expanded_query(text):\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": text}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\tresponse_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"ベクトル検索時の設定要素について教えてください\"\n",
    "expanded_query = generate_expanded_query(query)\n",
    "parsed_data = json.loads(expanded_query)\n",
    "parsed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for question in parsed_data[\"questions\"]:\n",
    "\tvector_query = VectorizableTextQuery(\n",
    "\t\ttext=question,\n",
    "\t\tk_nearest_neighbors=50,\n",
    "\t\tfields=\"vector\",\n",
    "\t)\n",
    "\t# Perform the search\n",
    "\tresults = search_client.search(\n",
    "\t\tsearch_text=query,\n",
    "\t\tvector_queries=[vector_query],\n",
    "\t\ttop=5,\n",
    "\t\tselect=\"chunk, title, key_phrases\",\n",
    "\t\tsearch_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    "\t)\n",
    "\tprint(\"query: \", question)\n",
    "\tfor result in results:\n",
    "\t\tprint(result)\n",
    "\tprint(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HyDE (Hypothetical Document Embeddings)\n",
    "- ユーザのクエリのコンテキストをとらえたい、かつサービスに特化したワードがクエリに含まれる可能性が高いため、フルテキスト検索＋ベクトル検索を組み合わせたHybrid検索を採用する。\n",
    "  - Hybrid検索のスコアはAzure AI Searchでは、Reciprocal Rank Fusion (RRF) が採用される。 \n",
    "- また、ユーザクエリから検索クエリを新しく生成する。\n",
    "  - クエリはユーザのクエリをスタンドアローンなクエリに変換する。\n",
    "  - また、ユーザのクエリに基づいて仮想的な応答をLLMで作成し、それをベクトル変換した結果を用いて検索をかけるHyDEを採用します。クエリを検索対象のベクトルにより近いものに変換することで、検索精度を高めることを狙った手法です。\n",
    "  - HyDEはLLMがまったく知識を持たないような領域だと役に立たない可能性があるため採用する際は注意してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_hypothetical_query(text):\n",
    "    hypothetical_gen_instruction = f\"\"\"Please write a passage to answer the question\n",
    "\tQuestion: {text}\n",
    "\tPassage:\n",
    "\t\"\"\"\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": \"You are an AI assistant.\"},\n",
    "\t\t{\"role\":\"user\",\"content\": hypothetical_gen_instruction}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\t# response_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"ベクトル検索時の設定要素について教えてください\"\n",
    "hypothetical_answer = generate_hypothetical_query(query)\n",
    "hypothetical_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_query = VectorizableTextQuery(\n",
    "\ttext=hypothetical_answer,\n",
    "\tk_nearest_neighbors=50,\n",
    "\tfields=\"vector\",\n",
    ")\n",
    "# Perform the search\n",
    "results = search_client.search(\n",
    "\tsearch_text=hypothetical_answer,\n",
    "\tvector_queries=[vector_query],\n",
    "\ttop=5,\n",
    "\tselect=\"chunk, title, key_phrases\",\n",
    "\tsearch_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    ")\n",
    "for result in results:\n",
    "\tprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 05_Generate-Answer\n",
    "検索インデックスから取得したものをコンテキストとして与えて、それをベースにした回答を生成させるプロンプトを設定します。\n",
    "プロンプトエンジニアリングに関する包括的なガイダンスは以下を参照ください。\n",
    "\n",
    "https://learn.microsoft.com/ja-jp/azure/ai-services/openai/concepts/prompt-engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "\n",
    "def generate_answer(query, context):\n",
    "    system_message = f\"\"\"\n",
    "    system:\n",
    "\tYou are an AI assistant that helps users answer questions given a specific context. You will be given a context and asked a question based on that context. Your answer should be as precise as possible and should only come from the context.\n",
    "\tPlease add citation after each sentence when possible in a form \"(Source: citation)\". \n",
    "\tcontext: {context}\n",
    "\tuser: \n",
    "\t\"\"\"\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": query}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\t# response_format={\"type\": \"json_object\"},\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_text = \"\"\n",
    "for result in results:\n",
    "\tcontext_text += result[\"chunk\"] + \" \"\n",
    "\n",
    "answer = generate_answer(query, context_text)\n",
    "answer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 06_Evaluation\n",
    "RAG の Evaluation は、「検索評価」と「生成評価」にわけて実施することが推奨される。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索評価 - 簡易評価\n",
    "- シンプルな検索評価として、検索結果の上位5件にユーザクエリを解決するための情報が含まれているかどうかを評価します。\n",
    "- クエリの種類は、想定されるエンドユーザーのクエリや、異なるドキュメントを答えとなるようなクエリを複数パターン用意します。\n",
    "  - 回答に複数の文が必要な抽象的な質問：\n",
    "  - 検索エンジンに一般的に入力されるものと同様の短縮されたクエリ：\n",
    "  - 回答が質問とは異なる単語やフレーズを使用しているクエリ：\n",
    "  - 回答が 1 つしかないクエリ\n",
    "  - 複数の内容を質問しているクエリ\n",
    "- ここではサンプルのため5パターンのクエリを用意しますが、包括的な評価をするためには、100件以上のパターンを用意することが推奨されます。（もちろん、ドキュメントの量やユーザのタスクによって異なるため、それぞれの要件にあわせて設計が必要です）\n",
    "  - [参考：評価用データセットの作成](https://github.com/microsoft/promptflow-resource-hub/blob/main/sample_gallery/golden_dataset/copilot-golden-dataset-creation-guidance.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query set\n",
    "queries = [\n",
    "\t\"AI Search について勉強しています。ベクトル検索時の設定要素について教えてください\",\n",
    "\t\"ハイブリッド検索　メリット\",\n",
    "\t\"Azure AI Search には、リランクのモデルが利用できるか？\",\n",
    "\t\"フルテキスト検索の取得は最大何件か\",\n",
    "\t\"Hybrid検索とセマンティックランカーの特徴と違いはなんですか？\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### シンプルクエリ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クエリを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Test for simple query\n",
    "for query in queries:\n",
    "    vector_query = VectorizableTextQuery(\n",
    "        text=query,\n",
    "        k_nearest_neighbors=50,\n",
    "        fields=\"vector\",\n",
    "    )\n",
    "\n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        search_text=query,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"chunk, title, key_phrases\",\n",
    "        search_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "\n",
    "    print(\"Query:\")\n",
    "    pprint.pprint(query)\n",
    "    print(\"\\nResults:\")\n",
    "    for result in results:\n",
    "        pprint.pprint(result)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価を実施\n",
    "1. 回答に複数の文が必要な抽象的な質問：\n",
    "\t- query: AI Search について勉強しています。ベクトル検索時の設定要素について教えてください\n",
    "\t- result: 合致するドキュメントが上位5番目までに含まれない（ベクトル検索についての説明は含まれるが、AI Search での設定要素に関する説明が足りていない）\n",
    "2. 検索エンジンに一般的に入力されるものと同様の短縮されたクエリ：\n",
    "\t- query: ハイブリッド検索　メリット\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "3. 回答が質問とは異なる単語やフレーズを使用しているクエリ：\n",
    "\t- query: Azure AI Search には、リランクのモデルが利用できるか？\n",
    "\t- result: 上位3番目のドキュメントが内容に合致\n",
    "4. 回答が 1 つしかないクエリ：\n",
    "\t- query: フルテキスト検索の取得は最大何件か\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "5. キーワードクエリ：\n",
    "\t- query: Hybrid検索とセマンティックランカーの特徴と違いはなんですか？\n",
    "\t- result: 上位1, 5番目のドキュメントが内容に合致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HyDE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "クエリを実行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "# Test for simple query\n",
    "for query in queries:\n",
    "    hypothetical_answer = generate_hypothetical_query(query)   \n",
    "    vector_query = VectorizableTextQuery(\n",
    "\t\ttext=hypothetical_answer,\n",
    "\t\tk_nearest_neighbors=50,\n",
    "\t\tfields=\"vector\",\n",
    "\t)\n",
    "\n",
    "    # Perform the search\n",
    "    results = search_client.search(\n",
    "        search_text=hypothetical_answer,\n",
    "        vector_queries=[vector_query],\n",
    "        top=5,\n",
    "        select=\"chunk, title, key_phrases\",\n",
    "        search_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    "    )\n",
    "\n",
    "    print(\"Query:\")\n",
    "    pprint.pprint(query)\n",
    "    print(\"\\nHyDE Query:\")\n",
    "    pprint.pprint(hypothetical_answer)\n",
    "    print(\"\\nResults:\")\n",
    "    for result in results:\n",
    "        pprint.pprint(result)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "評価を実施\n",
    "1. 回答に複数の文が必要な抽象的な質問：\n",
    "\t- query: AI Search について勉強しています。ベクトル検索時の設定要素について教えてください\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "2. 検索エンジンに一般的に入力されるものと同様の短縮されたクエリ：\n",
    "\t- query: ハイブリッド検索　メリット\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "3. 回答が質問とは異なる単語やフレーズを使用しているクエリ：\n",
    "\t- query: Azure AI Search には、リランクのモデルが利用できるか？\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "4. 回答が 1 つしかないクエリ：\n",
    "\t- query: フルテキスト検索の主とk数は最大何件か\n",
    "\t- result: 上位1番目のドキュメントが内容に合致\n",
    "5. キーワードクエリ：\n",
    "\t- query: Hybrid検索とセマンティックランカーの特徴と違いはなんですか？\n",
    "\t- result: 上位1, 5番目のドキュメントが内容に合致"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 検索評価 - 厳密な評価\n",
    "TBD\n",
    "- 評価指標の設計\n",
    "- クエリパターン\n",
    "- 評価用データの選定・設計"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 生成評価 - 簡易評価\n",
    "- シンプルな検索評価として、検索結果の上位5件にユーザクエリを解決するための情報が含まれているかどうかを評価します。\n",
    "- クエリの種類は、想定されるエンドユーザーのクエリや、異なるドキュメントを答えとなるようなクエリを複数パターン用意します。\n",
    "  - 回答に複数の文が必要な抽象的な質問：\n",
    "  - 検索エンジンに一般的に入力されるものと同様の短縮されたクエリ：\n",
    "  - 回答が質問とは異なる単語やフレーズを使用しているクエリ：\n",
    "  - 回答が 1 つしかないクエリ\n",
    "  - 複数の内容を質問しているクエリ\n",
    "- ここではサンプルのため5パターンのクエリを用意しますが、包括的な評価をするためには、100件以上のパターンを用意することが推奨されます。（もちろん、ドキュメントの量やユーザのタスクによって異なるため、それぞれの要件にあわせて設計が必要です）\n",
    "  - [参考：評価用データセットの作成](https://github.com/microsoft/promptflow-resource-hub/blob/main/sample_gallery/golden_dataset/copilot-golden-dataset-creation-guidance.md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define RAG Pipeline\n",
    "def rag_pipeline_with_hyde(query):\n",
    "\thypothetical_answer = generate_hypothetical_query(query)\n",
    "\tvector_query = VectorizableTextQuery(\n",
    "\t\ttext=hypothetical_answer,\n",
    "\t\tk_nearest_neighbors=50,\n",
    "\t\tfields=\"vector\",\n",
    "\t)\n",
    "\t# Perform the search\n",
    "\tresults = search_client.search(\n",
    "\t\tsearch_text=hypothetical_answer,\n",
    "\t\tvector_queries=[vector_query],\n",
    "\t\ttop=5,\n",
    "\t\tselect=\"chunk, title, key_phrases\",\n",
    "\t\tsearch_fields=[\"chunk\", \"title\", \"key_phrases\"],\n",
    "\t)\n",
    "\t\n",
    "\tcontext_text = \"\"\n",
    "\tfor result in results:\n",
    "\t\tcontext_text += result[\"chunk\"] + \" \"\n",
    "\n",
    "\treturn generate_answer(query, context_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query set\n",
    "queries = [\n",
    "\t\"AI Search について勉強しています。ベクトル検索時の設定要素について教えてください\",\n",
    "\t\"ハイブリッド検索　メリット\",\n",
    "\t\"Azure AI Search には、リランクのモデルが利用できるか？\",\n",
    "\t\"フルテキスト検索の取得は最大何件か\",\n",
    "\t\"Hybrid検索とセマンティックランカーの特徴と違いはなんですか？\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for query in queries:\n",
    "    start_time = time.time()\n",
    "    answer = rag_pipeline_with_hyde(query)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test query set\n",
    "queries = [\n",
    "\t\"AI Search において検索結果をハイライトする際に、単語レベルで設定することが可能か\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "for query in queries:\n",
    "    start_time = time.time()\n",
    "    answer = rag_pipeline_with_hyde(query)\n",
    "    end_time = time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Answer: {answer}\")\n",
    "    print(f\"Elapsed time: {elapsed_time} seconds\")\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
