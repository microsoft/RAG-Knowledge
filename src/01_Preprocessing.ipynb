{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01_Preprocessing\n",
    "Tips for data preprocessing to create search indexes for RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document format examples and extraction tools:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Format Examples and Extraction Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install PyMuPDF python-docx beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz  # PyMuPDF\n",
    "from docx import Document\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# PDF to text\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    pdf_document = fitz.open(pdf_path)\n",
    "    text = \"\"\n",
    "    for page_num in range(pdf_document.page_count):\n",
    "        page = pdf_document.load_page(page_num)\n",
    "        text += page.get_text()\n",
    "    return text\n",
    "\n",
    "\n",
    "# Word to text\n",
    "def extract_text_from_word(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "    return text\n",
    "\n",
    "\n",
    "# HTML to text\n",
    "def extract_text_from_html(html_path):\n",
    "    with open(html_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "        text = soup.get_text()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of usage\n",
    "example_extracted_text = extract_text_from_pdf(\"../data/02_article/Retrieval-Augmented-Generation-for-LLM.pdf\")\n",
    "example_extracted_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document Intelligence sample\n",
    "### Reference\n",
    "- https://techcommunity.microsoft.com/t5/ai-azure-ai-services-blog/unlocking-advanced-document-insights-with-azure-ai-document/ba-p/4109675\n",
    "- https://github.com/Azure-Samples/document-intelligence-code-samples/blob/main/Python(v4.0)/Retrieval_Augmented_Generation_(RAG)_samples/sample_figure_understanding.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv openai azure-ai-documentintelligence azure-identity pillow PyMuPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.ai.documentintelligence.models import ContentFormat\n",
    "from openai import AzureOpenAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "doc_intelligence_endpoint = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\")\n",
    "doc_intelligence_key = os.getenv(\"AZURE_DOCUMENT_INTELLIGENCE_KEY\")\n",
    "\n",
    "aoai_api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "aoai_api_key= os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_deployment_name = 'gpt-4o' # your model deployment name for GPT-4V\n",
    "aoai_api_version = '2024-02-01' # this might change in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Unify the format of headings in markdown text\n",
    "def convert_markdown_headings(markdown_text):\n",
    "    # Convert \"===\" headers to \"#\"\n",
    "    markdown_text = re.sub(r'^(.*?)\\n={3,}$', r'# \\1', markdown_text, flags=re.MULTILINE)\n",
    "\n",
    "    # Convert \"---\" headers to \"##\"\n",
    "    markdown_text = re.sub(r'^(.*?)\\n-{3,}$', r'## \\1', markdown_text, flags=re.MULTILINE)\n",
    "    \n",
    "    return markdown_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_layout(input_file_path, output_folder):\n",
    "    \"\"\"\n",
    "    Analyzes the layout of a document and extracts figures along with their descriptions, then update the markdown output with the new description.\n",
    "\n",
    "    Args:\n",
    "        input_file_path (str): The path to the input document file.\n",
    "        output_folder (str): The path to the output folder where the cropped images will be saved.\n",
    "\n",
    "    Returns:\n",
    "        str: The updated Markdown content with figure descriptions.\n",
    "\n",
    "    \"\"\"\n",
    "    document_intelligence_client = DocumentIntelligenceClient(\n",
    "        endpoint=doc_intelligence_endpoint, \n",
    "        credential=AzureKeyCredential(doc_intelligence_key),\n",
    "        headers={\"x-ms-useragent\":\"sample-code-figure-understanding/1.0.0\"},\n",
    "    )\n",
    "\n",
    "    with open(input_file_path, \"rb\") as f:\n",
    "        poller = document_intelligence_client.begin_analyze_document(\n",
    "            \"prebuilt-layout\", analyze_request=f, content_type=\"application/octet-stream\", output_content_format=ContentFormat.MARKDOWN \n",
    "        )\n",
    "\n",
    "    result = poller.result()\n",
    "    md_content = convert_markdown_headings(result.content)\n",
    "            \n",
    "    with open(f\"{output_folder}/{os.path.splitext(os.path.basename(input_file_path))[0]}.md\", 'w', encoding='utf-8') as f:\n",
    "        f.write(md_content)\n",
    "    \n",
    "    return md_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyze_layout(\"../data/01_aisearch_docs/azure-search-concept.pdf\", \"../output\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 【TBD】With Image\n",
    "https://github.com/Azure-Samples/document-intelligence-code-samples/blob/main/Python(v4.0)/Retrieval_Augmented_Generation_(RAG)_samples/sample_figure_understanding.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Option] Text standardization and normalization\n",
    "- Utilizing LLMs for text standardization and normalization is a highly effective approach.\n",
    "- It can extend the capabilities of traditional rule-based text transformation.\n",
    "- However, since LLMs do not guarantee the same output every time, traditional rule-based transformations should be used when output consistency is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using LLM such as GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import json\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "  api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version=\"2024-02-01\"\n",
    ")\n",
    "\n",
    "system_message = \"\"\"\n",
    "# Your Role\n",
    "You are an excellent AI assistant for proofreading text data. Your task is to ensure the provided text data is of high quality. You are only allowed to proofread. Adding or removing context from the original document is not allowed. Additionally, you cannot change the structure of the document.\n",
    "\n",
    "# Examples of Corrections\n",
    "- Grammar errors and typos\n",
    "- OCR misrecognitions\n",
    "- Inconsistencies in terminology and expressions\n",
    "\n",
    "# Your input\n",
    "text: \n",
    "\"\"\"\n",
    "\n",
    "def correct_text_gpt(text):\n",
    "    message_text = [\n",
    "\t\t{\"role\":\"system\",\"content\": system_message},\n",
    "\t\t{\"role\":\"user\",\"content\": text}\n",
    "\t]\n",
    "    completion = client.chat.completions.create(\n",
    "\t\tmodel=\"gpt-4o\", # model = \"deployment_name\"\n",
    "\t\tmessages = message_text,\n",
    "\t\ttemperature=0,\n",
    "\t\t)\n",
    "    return completion.choices[0].message.content\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using traditional rule-based text transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is example function to clean text data\n",
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<.*?>', '', text)\n",
    "    # Remove duplicate lines\n",
    "    lines = text.split(\"\\n\")\n",
    "    unique_lines = list(dict.fromkeys(lines))\n",
    "    return \"\\n\".join(unique_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
