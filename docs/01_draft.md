# RAGのTips

## データ前処理
RAGの検索インデックスを作成するためのデータ前処理の Tips

### ドキュメントからテキストデータを読み取る

- テキストデータ: ドキュメントから直接テキストデータを取得できる場合は、そのテキストデータを使用します。
  - PDF: 多くの技術文書や公式文書はPDF形式で提供されることが多い。PyMuPDFやpdfminer.sixを使用してテキストを抽出。
  - Word: ビジネス文書やレポートなどがWord形式で保存されていることが多い。python-docxを使用してテキストを抽出。
  - HTML: ウェブページやオンラインドキュメントからテキストを抽出する際に使用。BeautifulSoupを使用してテキストを抽出。
- AI-OCRが必要なパターン: ドキュメントが画像やPDFなどの形式で提供され、テキストデータを直接取得できない場合は、AI-OCR（Optical Character Recognition）を使用してテキストデータを抽出します。
  - Azure では、Azure AI Document Intelligence を利用できます。

#### Azure AI Document Intelligence でのドキュメント分析
Azure AI Document Intelligence は、単純なテキスト抽出だけでなく、階層的なドキュメント構造分析と図の検出を行ってくれます。高度な機械学習ベースのドキュメント分析 API を提供しており、 Layout モデルにより、高度なコンテンツ抽出機能とドキュメント構造分析機能の包括的なソリューションが提供されます。

- 階層文書構造分析: ドキュメントを Markdown 形式でセクションとサブセクションを分割し、ドキュメントのコンテキストの保持をサポートしてくれます。セマンティックチャンキングなど、コンテキストを維持したチャンキング戦略を可能にします。
- 図の検出: ページ全体の図形の空間的な位置を詳細に表示する boundingRegions などの主要なプロパティを抽出します。これにより、図やグラフを抽出し、マルチモーダルな RAG アーキテクチャを実現することが可能になります。

### テキストの標準化・正規化
元のデータが低品質だったり、OCRで読み取った場合は読み取りミスが発生する可能性があるため、データのクリーニング、標準化・正規化を行います。実施方法としては、従来のルールベース（正規表現など）とLLMを用いる方法が候補となります。
具体的には、以下のような処理を行います。

- 不要情報、重複情報の削除
  - ノイズやメタデータ、重複する段落などを除去
- 誤り・ミスの修正
  - 字認識ミス、文法エラー、タイポの修正
- OCRの場合：読み取りミスの修正
  - 誤認識された文字や単語を修正
- 用語・表現の揺らぎの修正
  - キーワードリストの作成、名寄せ処理をする

### Chunking Optimization
RAG においては、検索の効率性、大規模言語モデルの処理性能を考慮して、検索インデックスにデータを投入する際に、元のドキュメントを適切なサイズに分割（チャンキング）する検討を行います。
最近リリースされた大規模言語モデルは、入力可能なトークン数が大幅に増えているため、わざわざ RAG をしたり、そのためにチャンキングをしたりする必要はないという声も上がっています。しかし、コンテキスト長が長くなるほど、LLMの精度が下がるという事象も報告されているため、RAG およびそれを精度高く実現するためのチャンキングを検討することが推奨されます。
  - https://arxiv.org/abs/2402.14848

ただし、チャンキングの実施有無および、適切なサイズを見極めるのは非常に難しいプロセスです。ここでは、判断基準のガイダンスを提供します。

#### チャンキング実施の判断基準
##### チャンキングが必要なケース
1. 大規模データセットの検索
大量のデータから関連情報を検索する際、データを小さなチャンクに分割すると、検索精度と効率が向上します。例えば、大規模な文献データベースやニュース記事アーカイブから特定の情報を引き出す場合です。

2. 長文テキストの処理
大規模言語モデル（LLM）は一度に処理できるテキストの長さに制限があります。長文テキストをチャンキングすることで、モデルが一貫して処理できるサイズに分割し、適切な応答を生成しやすくなります。例えば、長いレポートや小説のようなドキュメントを解析する場合です。

##### チャンキングが必要ないケース
1. 元のドキュメントのサイズが大きくない場合
数1000トークンくらいであれば、LLMで十分コンテキストを解釈することが可能なため、チャンキングを必ずしもする必要はありません。

2. コンテキストがすでに何らかの単位で分割されている場合
ドキュメント自体が目的やコンテキスト単位で複数に分割されていたり、FAQなどすでに質問と回答がセットになっている場合は、わざわざ分割して、情報量や一貫性を減らす必要はありません。

#### チャンキング検討
##### ドキュメントの区切りが明確な場合
- 章、節、ヘッダーなどの明確な区切りでChunkを作成します。
  - 例: ドキュメントの章ごとに分割、都道府県ごとに分割、組織単位で分割

##### ドキュメントの区切りが明確でない場合
ドキュメントの区切りが明確でなく、どこで切るのが正しいか判断するのが難しい場合、以下の方法を検討します。
- Chunk を Overlapping
  - 文章が長くて一貫性が重要な場合、オーバーラップさせて分割することで、コンテキストを保ちながら情報を分割
  - Chunk の前後を一定割合重複（ドキュメントの性質により割合調整：まずは10~20％程度）させてChunkを作成。これにより、コンテキストを維持しつつ情報の正確性を保つ。
- 固定長でのChunk
  - 長いほう（数千）がいいパターンの具体例：長文の記事、研究論文、本の章など、詳細なコンテキストが重要な場合に適用。
    - 例: 学術論文の各セクション、技術ドキュメントの詳細な手順。
  - 短いほう（数百）がいいパターンの具体例：ユーザーが特定の情報をすばやく見つけたい場合、短いChunkが有効。
    - 例: FAQ、製品仕様、短いブログ記事。
- ベクトル検索を採用する際は、元のドキュメントをEmbeddingされた状態で、各ドキュメントを区別しやすくなるように分割単位、Overlapping範囲を考慮する
  - Embedding モデルの機能、次元を考慮する
    - ★Embedding のソースを追加する
    - https://note.com/daybreak_diary/n/n900593ef03ae
  - TBD：具体例は実ドキュメントをもとにあとから考える

#### メタデータ
- Chapter名、ドキュメント名を各Chunkに含む: 判別する要素を増やすため、各ChunkにChapter名やドキュメント名を含めます。これにより、検索時に特定のChapterやドキュメントに関連する情報をより簡単に見つけることができます。


#### Chunking Evaluation
チャンキングは一度で最適なサイズを見つけるのは困難です。ドキュメントをサンプリングして、何パターンか評価するのがよいでしょう。
評価指標は、[RAGの評価設計](#RAGの評価設計)で詳細に説明しますが、以下のリンクのような評価をします。
  - https://learn.microsoft.com/en-us/azure/ai-studio/concepts/evaluation-metrics-built-in?tabs=warning

評価を効率的に実施する方法として、 LlamaIndex の Response Evaluation module を使うと、複数の Chunk サイズのテスト（パフォーマンス、レスポンスタイム）を評価することが可能です。
  - https://www.llamaindex.ai/blog/evaluating-the-ideal-chunk-size-for-a-rag-system-using-llamaindex-6207e5d3fec5


#### Advanced Method
- Semantic Chunking: 文ごとにEmbeddingの類似性を取得して、類似度に差がある箇所をブレークポイントとすることで、意味を持ったチャンク分割を行う
  - https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/semantic-chunker/
  - https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/semantic-chunker/


### Embedding Model の選定
テキスト埋め込みは、単語、フレーズ、またはドキュメント全体のセマンティクスまたは意味をキャプチャするテキストの数値表現です。これらは、感情分析、テキスト分類など、多くのNLPタスクの基礎となります。

text-embedding-3-small は、レイテンシーとストレージに最適化されています。一方、text-embedding-3-large は精度を高めるための優れたオプションであり、新しい dimensions パラメーターを利用して、全体的なパフォーマンスに影響を与えることなく、ネイティブ サイズの 3072 ではなく 1536 に維持することもできます。

#### 選定の観点
- 埋め込み元のドキュメント：テキスト、画像、マルチモーダル
- 精度（ベンチマーク）
- 次元
- レイテンシー
- 言語
- カットオフ
- 価格

#### ベンチマーク
MTEB: このベンチマークは、検索、分類、再ランク付け、クラスタリング、要約など、56 の異なるタスクをカバーしています。目標に応じて、ユースケースを表すタスクの正確なサブセットを確認できます。
BEIR: このベンチマークは、検索タスクに焦点を当てており、ファクトチェック、生物医学的な質問、重複する質問の検出など、さまざまな種類とドメインの質問の形で複雑さを増しています。MTEBは主にBEIRベンチマークのスーパーセットであるため、ほとんどの議論でMTEBに焦点を当てます。



## インデックス設計
インデックス設計についてまとめます。

### インデックスの単位
#### インデックス分割観点
- サービス側の制約（ストレージサイズ、ベクトルDBデータ量）
- セキュリティ観点（インデックスレベルでドキュメントをわけて権限制御させる）
- データソース（M365, Azure, 3rd Party Storageなど）
- データ種別（テキスト、イメージなど）
- どのようにデータを検索したいか（全データを横断的に検索してランク付けしたいか、データソースやデータ種別ごとにランクづけしたいか）
- 運用観点（元のドキュメントの更新タイミング、ライフサイクル）

#### 具体例
- インデックスを１つにするとクエリは１回で済むので楽ですが、元のドキュメントの更新タイミング、ライフサイクルが異なる場合は、インデックスの更新の設計がやや煩雑になるではと思います。
- 一方でインデックスをソースごとに複数にわけると、各インデックスの管理はシンプルになりますが、クエリの回数が増えるのと、取得したデータをアプリ側でリランキングしたり、LLMにどれが関連性が高いかを判断させたりする手間が増えます。

### フィールド定義
- Retrievable、Searchable にすべき項目
- フィルタとして持たせるべき項目
  - ファイル名、ページ数
  - カテゴリ（部署名、商品カテゴリなど）
- 要約やキーフレーズを項目として持たせるか？
- Embedding対象の列をどれにするか？判断基準は？
  - 基本的にはコンテキストが重要になる項目（キーワードのみだとあまり意味がない）
  - https://learn.microsoft.com/en-us/azure/search/vector-store
- Analyzer
  - クエリを検索エンジンが解釈するために、Analyzer が必要になる。
    - Azure AI Search では、デフォルトは「Standard Lucene Analyzer」
  - どのような場合に別のアナライザーを使うべきか？
  - Function Calling の引数が英語になる
    - ユーザの質問をそのまま入れることができるか？（日本語？）
    - 裏の検索・クエリをすべて英語にするか？
  - マルチ言語のアプリケーションの場合どうするか？

### データインポート戦略
#### インポート方式
検索インデックスに対して、データをインポートする方式を検討する必要がある。検索エンジンが
- PUSH型：検索エンジンがサポートしている、APIやSDKを使って、ユーザがデータを検索インデックスにインポートする
- PULL型：検索エンジンがサポートしている外部データソースへのコネクターやクローラーを使ってデータをインポートする。

Azure AI Search では、2種類のデータインポート方法が用意されている。どのような使い分けをするべきか？
  https://learn.microsoft.com/en-us/azure/search/search-what-is-data-import
- PUSH型
  - インデクサーが対応していないデータソース（データソースの種類に制限はない）
  - 頻繁なドキュメント更新、リアルタイムな反映が必要なケース。実行頻度に制限はありません。変更は何度でもインデックスにプッシュできます。待機時間が短い要件を持つアプリケーション (たとえば、インデックスを製品在庫の変動と同期させる必要がある場合) では、プッシュ モデルが唯一のオプションです。
  - セキュリティのコントロール（完全に制御可能）
- PULL型（インデクサーを使用する）
  - インデクサーが対応しているデータソースのみ
  - データインポート運用をローコードで実現したい
  - スキルセットを使いたい

#### 更新タイミング
- ファイルの更新日をもってどのように更新していくのがよいか？
  - どの行が更新対象になるかを判断するのが難しい。
    - 同じドキュメント、タイトル、更新日
    - ★STU：Data＆AI、詳しい人に運用方法を聞く

#### スキルセット（AI Enrichment）
Azure AI Search には、生の形式で検索できないコンテンツを処理するために Azure AI サービスと統合する"AI エンリッチメント" という機能があります。
生のコンテンツが、非構造化テキスト、画像コンテンツ、または言語検出と翻訳を必要とするコンテンツの場合は、エンリッチメントが有用です。

##### Built-in Skillset
- 多言語検索の場合の翻訳と言語検出
- テキストの大きなチャンクからユーザー名、場所、その他のエンティティを抽出するエンティティ認識
- 重要な用語を識別して出力するキー フレーズ抽出
- バイナリ ファイル内の印刷されたテキストと手書きのテキストを認識する光学式文字認識 (OCR)
- 画像の内容を説明し、説明を検索可能なテキスト フィールドとして出力する画像分析

[ユースケース](https://learn.microsoft.com/en-us/azure/search/cognitive-search-concept-intro#use-cases-for-built-in-skills)

##### Custom Skillset
[ユースケース](https://learn.microsoft.com/en-us/azure/search/cognitive-search-concept-intro#use-cases-for-custom-skills)


## クエリ設計
### 検索手法
検索エンジンやデータベースは以下のようなメジャーな検索手法があり、用途やデータソースに応じて、適切な検索手法を選択する必要があります。

1. キーワード検索：
- 解説：検索クエリとして入力されたキーワードに基づいて検索結果を返します。入力された単語が文書内に含まれているかどうかを照合します。
- ユースケース・使いどころ：
  - 情報検索：ニュース記事やブログの検索。
  - 製品検索：オンラインショッピングサイトでの製品検索。
  - 基本的な情報取得：辞書や百科事典の検索。

2. フルテキスト検索：
- 解説：文書全体を対象にし、キーワードだけでなく、フレーズや部分一致などを考慮して検索します。インデックスを使用して高速化されています。
- ユースケース・使いどころ：
  - ドキュメント管理システム：契約書や技術文書の検索。
  - 法律データベース：法令や判例の検索。
  - 学術論文の検索：全文検索により詳細な内容のマッチングが可能。

3. ベクトル検索：
- 解説：文書やクエリを数値ベクトルに変換し、これらのベクトル間の類似度を計算することで検索を行います。主に自然言語処理（NLP）に基づく手法です。
- ユースケース・使いどころ：
  - 類似文書検索：学術論文やニュース記事の類似文書検索。
  - レコメンデーションシステム：ユーザーの好みに基づくコンテンツ推薦。
  - 質問応答システム：質問に対する最も適切な回答を見つける。

4. グラフ検索：
- 解説：データをノードとエッジのグラフ構造で表現し、ノード間の関係性を元に検索を行います。特にネットワークや接続性の高いデータに有効です。
- ユースケース・使いどころ：
  - ソーシャルネットワーク解析：ユーザー間の関係性やコミュニティ検出。
  - 推薦エンジン：ユーザーとアイテムの関係性を基にした推薦。
  - 知識グラフ：企業内の知識データベースやエンタープライズサーチ。


### Azure AI Search における検索手法
- フルテキスト検索
  - 専門用語が多い場合は、事前にキーワードリストを作っておいて補完する
- ベクトル検索

### 高度な検索手法 
- Hybrid 検索：
  - 何を Hybridさせるか？（どの検索手法の結果をどのようにランク付けするか）
  - 【Azure AI Search】Threshhold の調整など、new featureを追加
- Semantic Ranker：Reranking
  - なぜ必要か？どのような効果があるか？
  - 設計要素は？（アルゴリズム）


#### クエリ設計
- クエリ拡張
  - 質問に情報を付加する（入力クエリをLLMを使って洗練させる（抽象的な内容を具体化するなど））
  - 複数個のクエリを追加する
  - 複数の検索結果の中で、元の質問と一番近いものを判断させる
- HyDE（Hypothetical Document Embeddings）：LLMに仮の回答を作らせて、その仮の回答をベクトル化して検索に使う
- RAG Fusion：入力クエリに類似したクエリを複数生成し、それぞれのクエリの検索結果を統合する
  - https://blog.langchain.dev/query-transformations/
- Iterative Retrieval-Generator RAG：1つのクエリをインプットにして、推論を段階的に繰り返す（前の推論結果を次の入力にして、段階的にユーザのクエリを解決させる）

- Index を作るときに使ったReviseと同じようにさせる、Indexのデータを取るのが目的のため、どのようにクエリを作るかを考えるべき。
  - どのような表現に寄せるか？
    - 専門性高く？
    - 低く？
  - マニュアルは正しい日本語、質問は自然文（好きな形）。どちらの寄せるか？

- 複数の質問が入ってきた場合：Tips
  - アプリで対処するか？
  - FunctionCallingで複数回呼ぶ
    - 質問文に分割させる
  - クエリ拡張




## RAGの評価設計
### 評価対象
- 検索結果（Retrieverの評価）：検索結果に期待する情報が含まれているか？
  - メトリックは？
  - 上位に結果が返ってくるかどうか？
  - Regression Test: インデックスを変えた際に、他のクエリに影響がでてないか
- 生成結果：検索結果をもとに質問に最適な回答が生成されているか？
  - メトリックは？
  - Modelの性能　→ Evaluationツール


ユーザの質問が悪いケースもある。（インデックスの問題ではない場合もある）

- Youtubeからインデックスを作成したい場合
  - テキスト化
  - 時間
  - 画面キャプション
  - 再生数
  - フォロワー数

- マニュアルからインデックスを作成したい場合
  - Serface


### 評価ツール
- PromptflowのEvaluation



## Memo: AI Service の選択
少しでも回答の精度をあげるための
- Cog Service の機能
- Embedding model
- 最後の生成（回答）は頭がいいモデルがよい（いまだとgpt4oとか）
- 元のテキストやタスクが簡単な場合はgpt3.5でも十分な場合がある
- 一番いいものからはじめて、だんだん安いモデルに変えていって、ROIを最適化していくのがよい

チャンクを大前提で書かない
  FAQであれば、答えがあるからLLM必要ない（検索だけで済む可能性がある）

　判断基準はインデックスにあるデータ、

- マニュアル
- 論文
  - １つの論文の内容を知りたい：１つのテーマを論じているため、各セクションごとに
  - 論文自体を探したい（あるテーマにおいて）→どの論文かの情報のみあればよい

★追加：
現状使えるもの：DI、GPT4V,4o
今後の機能拡張：各LLM、SLM、AI Service の機能拡張、性能向上など


## Reference
- 